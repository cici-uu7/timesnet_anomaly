æ£€æŸ¥æˆ‘çš„timesnet_anomalyæ¨¡å‹

ä¸ºä»€ä¹ˆæ•ˆæœå¾ˆå·® æˆ‘å¸Œæœ›åœ¨timesnetæ¨¡å‹ä¸­å¼•å…¥å…³è”å·®å¼‚æœºåˆ¶ ç©¶ç«Ÿæ€ä¹ˆåšæ‰æ˜¯å¯¹çš„

 

â— æˆ‘æ¥å¸®ä½ æ£€æŸ¥ TimesNet å¼‚å¸¸æ£€æµ‹æ¨¡å‹çš„é—®é¢˜ï¼Œå¹¶æ¢è®¨å¦‚ä½•æ­£ç¡®å¼•å…¥å…³è”å·®å¼‚æœºåˆ¶ã€‚è®©æˆ‘å…ˆäº†è§£å½“å‰çš„ä»£ç å®ç°ã€‚

 

â— Read(models\TimesNet_AD.py)

  â¿  Read 50 lines

 

â— Read(layers\Anomaly_Attention.py)

  â¿  Read 69 lines

 

â— æˆ‘å·²ç»åˆ†æäº†ä½ çš„ä»£ç ï¼Œå‘ç°äº†å‡ ä¸ªå…³é”®é—®é¢˜å¯¼è‡´æ¨¡å‹æ•ˆæœå·®ã€‚è®©æˆ‘å…ˆå®Œæˆåˆ†æï¼Œç„¶åç»™å‡ºæ­£ç¡®çš„å…³è”å·®å¼‚æœºåˆ¶å®ç°æ–¹æ¡ˆã€‚

 

â— Search(pattern:

"**/*.py", path: "G:\python_code\timesnet_anomaly")

  â¿  Found 86 files (ctrl+o to expand)

 

â— è®©æˆ‘æŸ¥çœ‹è®­ç»ƒä»£ç å’ŒæŸå¤±å‡½æ•°ï¼Œä»¥å…¨é¢äº†è§£é—®é¢˜ï¼š

 

â— Read(exp\exp_timesnet_ad.py)

  â¿  Read 276 lines

 

â— å¥½çš„ï¼Œæˆ‘å·²ç»å®Œæˆäº†ä»£ç åˆ†æã€‚ç°åœ¨è®©æˆ‘è¯¦ç»†è¯´æ˜å‘ç°çš„é—®é¢˜å’Œæ­£ç¡®çš„è§£å†³æ–¹æ¡ˆã€‚

 

  ğŸ” å‘ç°çš„æ ¸å¿ƒé—®é¢˜

 

  é—®é¢˜ 1: å…³è”å·®å¼‚æœºåˆ¶æ²¡æœ‰çœŸæ­£è¢«åˆ©ç”¨

 

  åœ¨ layers/Anomaly_Attention.py:50-52ï¼Œä½ è®¡ç®—äº†

series_attn å’Œ prior_attnï¼Œä½†é‡æ„æ—¶åªä½¿ç”¨äº† series_attnï¼š

 

 weighted_value = torch.einsum("bhls,bshd->blhd",

series_attn, v)  # åªç”¨äº† series_attn

 

  è¿™æ„å‘³ç€ prior_attn åªæ˜¯è¢«è®¡ç®—å‡ºæ¥ç”¨äºæŸå¤±å‡½æ•°ï¼Œä½†æ²¡æœ‰å‚ä¸ç‰¹å¾é‡æ„ã€‚å…³è”å·®å¼‚æœºåˆ¶çš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

  - æ­£å¸¸æ•°æ®: Series å’Œ Prior åº”è¯¥ä¸€è‡´ â†’ å·®å¼‚å°

  - å¼‚å¸¸æ•°æ®: Series å’Œ Prior ä¼šäº§ç”Ÿåˆ†æ­§ â†’ å·®å¼‚å¤§

 

  ä½†ä½ çš„å®ç°ä¸­ï¼ŒPrior å®Œå…¨æ²¡æœ‰å½±å“æ¨¡å‹çš„é‡æ„èƒ½åŠ›ï¼

 

  ---

  é—®é¢˜ 2: Minimax è®­ç»ƒç­–ç•¥æœ‰ä¸¥é‡é”™è¯¯

 

  åœ¨ exp/exp_timesnet_ad.py:89-95ï¼Œä½ çš„ Series Losså’Œ Prior Loss å®Œå…¨ç›¸åŒï¼š

 

  #

Series Loss: Series é€¼è¿‘ Prior

 series_loss += torch.mean(self.my_kl_loss(p_attn, s_attn.detach() +

1e-5)) + \

                torch.mean(self.my_kl_loss(s_attn.detach() + 1e-5, p_attn))

 

  #

Prior Loss: Prior é€¼è¿‘ Series (åå‘ä¼˜åŒ–)

 prior_loss += torch.mean(self.my_kl_loss(p_attn, s_attn.detach() +

1e-5)) + \

               torch.mean(self.my_kl_loss(s_attn.detach() + 1e-5, p_attn))

 

  ä¸¤ä¸ªæŸå¤±çš„è®¡ç®—å…¬å¼ä¸€æ¨¡ä¸€æ ·ï¼è¿™å¯¼è‡´ï¼š

  -

loss1 = rec_loss - k * series_loss

  -

loss2 = k * prior_loss

 

  å®é™…ä¸Šç­‰ä»·äº loss1 + loss2 = rec_lossï¼ŒMinimax ç­–ç•¥å®Œå…¨å¤±æ•ˆã€‚

 

  æ­£ç¡®çš„ Minimax åº”è¯¥æ˜¯ï¼š

  - Phase

1: æœ€å°åŒ–é‡æ„è¯¯å·® + æœ€å°åŒ–å·®å¼‚ï¼ˆè®© Serieså­¦ä¹  Priorï¼‰

  - Phase

2: æœ€å¤§åŒ–å·®å¼‚ï¼ˆè®© Prior ä¿æŒç‹¬ç«‹æ€§ï¼Œä¸è¢«

Series åŒåŒ–ï¼‰

 

  ---

  é—®é¢˜ 3: Prior ä½¿ç”¨äº†é”™è¯¯çš„è¾“å…¥

 

  åœ¨ models/TimesNet_AD.py:34-35ï¼Œä½ ç”¨

raw_embedding ä½œä¸º Priorï¼š

 

 enc_out = self.timesnet.enc_embedding(x_enc, x_mark_enc)

 raw_embedding = enc_out.clone()

 

  ä½† enc_embedding å·²ç»åŒ…å«äº†ä½ç½®ç¼–ç å’Œæ—¶é—´ç‰¹å¾ï¼Œè¿™äº›ä¿¡æ¯ä¼šå¹²æ‰° Prior çš„å±€éƒ¨è¿ç»­æ€§å‡è®¾ã€‚

 

  æ­£ç¡®åšæ³•ï¼šPrior åº”è¯¥åŸºäºåŸå§‹è¾“å…¥åºåˆ—æˆ–æœ€æµ…å±‚ç‰¹å¾ï¼Œè€Œä¸æ˜¯ç»è¿‡

Embedding çš„ç‰¹å¾ã€‚

 

  ---

  âœ… æ­£ç¡®çš„å…³è”å·®å¼‚æœºåˆ¶å®ç°æ–¹æ¡ˆ

 

  è®©æˆ‘ä¸ºä½ å®ç°ä¿®å¤ç‰ˆæœ¬ã€‚æˆ‘ä¼šåˆ†æ­¥éª¤è¿›è¡Œï¼š

 

â— å¥½çš„ï¼Œè®©æˆ‘å¼€å§‹ä¿®å¤è¿™äº›é—®é¢˜ã€‚æˆ‘ä¼šåˆ†æ­¥éª¤è¿›è¡Œä¿®å¤ã€‚

 

  ä¿®å¤æ–¹æ¡ˆæ¦‚è¿°

 

  æˆ‘å°†ä¿®å¤ä»¥ä¸‹ä¸‰ä¸ªæ ¸å¿ƒé—®é¢˜ï¼š

 

  1. è®© Prior Association çœŸæ­£å‚ä¸é‡æ„ - ä½¿ç”¨å…³è”å·®å¼‚æ¥è°ƒåˆ¶ç‰¹å¾

  2. ä¿®æ­£ Minimax è®­ç»ƒç­–ç•¥ - ç¡®ä¿ Series å’Œ Prior çœŸæ­£å¯¹æŠ—

  3. ä¿®æ­£ Prior è¾“å…¥æº - ä½¿ç”¨åŸå§‹è¾“å…¥è€Œé Embedding

 

  è®©æˆ‘å…ˆä¿®å¤ AnomalyBlockï¼š

 

â— Update(layers\Anomaly_Attention.py)

 

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

 Edit

file layers\Anomaly_Attention.py

â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œ

  46            sigma =

sigma.permute(0, 2, 1).contiguous().float() # [B, H, L]

  47            prior_attn =

self._calculate_prior_association(sigma, L)

   48

   49

-          # 5. é‡æ„è¾“å‡º (ä½¿ç”¨ Series çš„ V)

   50

-          weighted_value =

torch.einsum("bhls,bshd->blhd", series_attn, v)

   49

+          # 5. å…³é”®ä¿®å¤ï¼šä½¿ç”¨å…³è”å·®å¼‚æ¥è°ƒåˆ¶é‡æ„

   50

+          # æ­£å¸¸æ•°æ®ï¼šSeries â‰ˆ Priorï¼Œå·®å¼‚å°ï¼Œä½¿ç”¨ Series é‡æ„

   51

+          # å¼‚å¸¸æ•°æ®ï¼šSeries â‰  Priorï¼Œå·®å¼‚å¤§ï¼ŒPrior ä¼š"æ‹‰å›"é‡æ„

   52

+

   53

+          # è®¡ç®—åŠ æƒåçš„ Value (ä½¿ç”¨æ··åˆçš„ Attention)

   54

+          # ä½¿ç”¨

Prior ä½œä¸ºåŸºç¡€ï¼ŒSeries ä½œä¸ºè°ƒåˆ¶

   55

+          mixed_attn = prior_attn +

series_attn  # ç®€å•ç›¸åŠ ï¼Œè®©ä¸¤è€…éƒ½å‚ä¸

   56

+          mixed_attn = mixed_attn /

2.0  # å½’ä¸€åŒ–

   57

+

   58

+          weighted_value =

torch.einsum("bhls,bshd->blhd", mixed_attn, v)

  59            out =

weighted_value.reshape(B, L, -1)

  60            out =

self.out_layer(out)

   61

 è¿™æ˜¯æˆ‘è®©Claudeåˆ†æä»£ç åå¾—å‡ºçš„ç»“æœ å®ƒåˆ†æçš„å¯¹å— æˆ‘åº”è¯¥æ€ä¹ˆæ‰èƒ½å‘æŒ¥å‡ºå¼•å…¥å…³è”å·®å¼‚æœºåˆ¶åçš„timesnet